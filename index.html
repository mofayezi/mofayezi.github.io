<!DOCTYPE HTML>
<html lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

        <title>Mohammadreza Mofayezi</title>

        <meta name="author" content="Mohammadreza Mofayezi">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="shortcut icon" href="assets/img/icon.jpg" type="image/x-icon">
        <link rel="stylesheet" type="text/css" href="assets/css/main.css">

    </head>

    <body>
        <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                        <tr style="padding:0px">
                            <td style="padding:2.5%;width:63%;vertical-align:middle">
                                <p class="name" style="text-align: center;">
                                    Mohammadreza Mofayezi
                                </p>
                                <p>
                                    I am a Computer Science PhD student at the <a href="https://www.utoronto.ca">University of Toronto</a> and <a href="https://vectorinstitute.ai">Vector Institute</a>, supervised by Prof. <a href="https://www.cs.toronto.edu/~nandita/">Nandita Vijaykumar</a> in the <a href="https://www.embarclab.com">embARC Lab</a>. 
                                </p>
                                <p>
                                    Previously, I was fortunate to work as an Augmented Reality Developer at <a href="https://twitter.com/MadLlamaGames">MadLlama</a> game studio and conduct research under the supervision of Prof. <a href="https://www.epfl.ch/labs/vita/">Alexandre Alahi</a> at EPFL, Prof. <a href="https://gvrl.mpi-inf.mpg.de">Adam Kortylewski</a> at MPI, and do my B.Sc. thesis with Dr. <a href="https://llp.berkeley.edu/asgari/">Ehsaneddin Asgari</a> at Sharif University of Technology.
                                </p>
                                <p style="text-align:center">
                                    <a href="mailto:mofayezi@cs.toronto.edu">Email</a> &nbsp;/&nbsp;
                                    <a href="assets/pdf/cv.pdf">CV</a> &nbsp;/&nbsp;
                                    <a href="https://scholar.google.com/citations?user=8R3g1hkAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                                    <a href="https://twitter.com/marmofayezi">Twitter</a> &nbsp;/&nbsp;
                                    <a href="https://github.com/mofayezi/">GitHub</a> &nbsp;/&nbsp;
                                    <a href="https://www.linkedin.com/in/marmofayezi/">LinkedIn</a>
                                </p>
                            </td>
                            <td style="padding:2.5%;width:40%;max-width:40%;padding-top: 10%;">
                                <img style="width:90%;max-width:90%;border-radius: 20px;" alt="profile photo" src="assets/img/profile.jpg" class="hoverZoomLink">
                            </td>
                        </tr>
                    </tbody></table>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                        <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                                <h2>Research</h2>
                                <p>
                                    My research focuses on efficient <b>machine learning</b> and <b>computer vision</b>.
                                </p>
                            </td>
                        </tr>
                    </tbody></table>
                
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                        <tr>
                            <td style="padding:20px;width:25%;vertical-align:middle">
                                <div class="one">
                                    <div class="two" id='m3face_image'>
                                        <img src='assets/img/publication_preview/m3face.png' width="180"></div>
                                    <img src='assets/img/publication_preview/m3face.png' width="180">
                                </div>
                            </td>
                            <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="https://arxiv.org/abs/2402.02369">
                                    <span class="papertitle">M<sup>3</sup>Face: A Unified Multi-Modal Multilingual Framework for Human Face Generation and Editing</span>
                                </a>
                                <br>
                                <strong>Mohammadreza Mofayezi</strong>,
                                <a href="https://github.com/Reza-Alipour">Reza Alipour</a>,
                                <a href="https://github.com/mohammadalikakavand">Mohammad Ali Kakavand</a>,
                                <a href="https://scholar.google.com/citations?user=lIVvIFsAAAAJ&hl=en">Ehsaneddin Asgari</a>
                                <br>
                                <em>arXiv</em>, 2024
                                <br>
                                <a href="https://arxiv.org/abs/2402.02369">arXiv</a>
                                /
                                <a href="assets/bibliography/m3face.bib">bibtex</a>
                                <!-- / -->
                                <!-- <a href="https://github.com/mofayezi/m3face">code</a>
                                / -->
                                <!-- <a href="https://drive.google.com/file/d/1Ed0UE1mGoiqKKe5Xw5N6vxa2eOYpwgmb/view?usp=sharing">poster</a> -->
                                <p></p>
                                <p>
                                    By generating multi-modal conditions with a text prompt, we offer an option to use additional modalities without requiring them.
                                </p>
                            </td>
                        </tr>
                    </tbody></table>
                
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                        <tr>
                            <td style="padding:20px;width:25%;vertical-align:middle">
                                <div class="one">
                                    <div class="two" id='robutext_image'>
                                        <img src='assets/img/publication_preview/robutext.png' width="180"></div>
                                    <img src='assets/img/publication_preview/robutext.png' width="180">
                                </div>
                            </td>
                            <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="http://arxiv.org/abs/2304.02963">
                                    <span class="papertitle">Benchmarking Robustness to Text-Guided Corruptions</span>
                                </a>
                                <br>
                                <strong>Mohammadreza Mofayezi</strong> and
                                <a href="https://scholar.google.com/citations?user=ascG1x0AAAAJ&hl=en">Yasamin Medghalchi</a>
                                <br>
                                <em>CVPRW</em>, 2023
                                <br>
                                <a href="http://arxiv.org/abs/2304.02963">arXiv</a>
                                /
                                <a href="assets/bibliography/robutext.bib">bibtex</a>
                                /
                                <a href="https://github.com/mofayezi/RobuText">code</a>
                                /
                                <a href="https://drive.google.com/file/d/1Ed0UE1mGoiqKKe5Xw5N6vxa2eOYpwgmb/view?usp=sharing">poster</a>
                                <p></p>
                                <p>
                                    Towards evaluating the robustness of image classifiers to text-guided corruptions generated with diffusion models. 
                                </p>
                            </td>
                        </tr>
                    </tbody></table>
                
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                        <tr>
                            <td style="padding:20px;width:25%;vertical-align:middle">
                                <div class="one">
                                    <div class="two" id='deposit_image'>
                                        <img src='assets/img/publication_preview/deposit.png' width="180"></div>
                                    <img src='assets/img/publication_preview/deposit.png' width="180">
                                </div>
                            </td>
                            <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="http://arxiv.org/abs/2210.05669">
                                    <span class="papertitle">A generic diffusion-based approach for 3D human pose prediction in the wild</span>
                                </a>
                                <br>
                                <a href="https://saeedsaadatnejad.github.io">Saeed Saadatnejad</a>,
                                <a href="https://scholar.google.com/citations?user=7rPSedUAAAAJ&hl=en">Ali Rasekh</a>,
                                <strong>Mohammadreza Mofayezi</strong>,
                                <a href="https://scholar.google.com/citations?user=ascG1x0AAAAJ&hl=en">Yasamin Medghalchi</a>,
                                <a href="https://www.linkedin.com/in/sara-rajabzadeh/">Sara Rajabzadeh</a>,
                                <a href="https://scholar.google.com/citations?hl=fr&user=wqBOFKEAAAAJ&&hl=en">Taylor Mordan</a>,
                                <a href="https://people.epfl.ch/alexandre.alahi?lang=en">Alexandre Alahi</a>
                                <br>
                                <em>ICRA</em>, 2023
                                <br>
                                <a href="http://arxiv.org/abs/2210.05669">arXiv</a>
                                /
                                <a href="assets/bibliography/deposit.bib">bibtex</a>
                                /
                                <a href="https://github.com/vita-epfl/DePOSit">code</a>
                                /
                                <a href="https://github.com/vita-epfl/DePOSit/blob/main/docs/poster_icra23.pdf">poster</a>
                                <p></p>
                                <p>
                                    A unified diffusion-based framework for human motion prediction and reconstruction with incomplete and noisy data.
                                </p>
                            </td>
                        </tr>
                    </tbody></table>
                        
                    <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
                    <tr>
                        <td>
                        <h2>Academic Services</h2>
                        </td>
                    </tr>
                    </tbody></table> -->

                    <!-- <table width="100%" align="center" border="0" cellpadding="20"><tbody>
                            
                            <tr>
                            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
                            <td width="75%" valign="center">
                                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                                <br>
                                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                                <br>
                                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                                <br>
                                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                                <br>
                                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                                <br>
                                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                            </td>
                            </tr>            
                            
                    </tbody></table> -->

                    <!-- Footer -->
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tr>
                        <td style="padding:0px">
                        <br>
                        <p style="text-align:center;font-size:small;">Design and source code from <a style="font-size:small;"
                            href="https://jonbarron.info">Jon Barron</a>'s website.
                        </p>
                        </td>
                    </tr>
                    </table>
                </td>
            </tr>
        </table>
    </body>
</html>